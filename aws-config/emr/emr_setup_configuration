
# EMR - Edit Software settings - Enter configuration
[
  {"classification":"spark",
   "properties":{
     "maximizeResourceAllocation":"true"}},
  {"classification":"spark-env",
   "configurations":[{
     "classification":"export",
     "properties":{
       "PYSPARK_PYTHON":"./environment/bin/python",
       "PYSPARK_DRIVER_PYTHON":"/mnt1/miniconda/envs/lab/bin/ipython"}}],
   "properties":{}},
  {"classification":"spark-defaults",
   "properties":{
     "spark.sql.execution.arrow.pyspark.enabled":"true",
     "spark.sql.session.timeZone":"UTC",
     "spark.sql.shuffle.partitions":"20000",
     "spark.dynamicAllocation.enabled":"true",
     "spark.sql.parquet.enableVectorizedReader":"false"}}]

# command to start a Spark session (written to .bashrc in startup.sh)
pyspark --archives /mnt1/environment.tar.gz#environment
